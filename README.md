# ğŸ“ IntelliTeach-AI â€” Round 2 Prototype (IIT Bombay Upskill India)

IntelliTeach-AI evaluates teaching videos and generates an objective scorecard across:

- Clarity  
- Engagement  
- Confidence  
- Technical Depth  
- Interaction Quality  

This Round-2 prototype demonstrates a complete end-to-end AI workflow using free-tier transcription and scoring models, a structured backend, and a functional frontend UI.

---

# ğŸš€ Features

- Upload a video (MP4)  
- Automatic transcription via AssemblyAI (Free Tier)  
- Scoring via Groq LLaMA (Free Tier)  
- JSON output with category scores, overall score, and improvement suggestions  
- Transcript preview  
- Streamlit frontend  
- FastAPI backend  
- Complete documentation in `/docs`  
- Hackathon-compliant folder structure  

---

# ğŸ—ï¸ Architecture Overview

### Frontend â€” `src/frontend/app.py`
Streamlit interface for:
- Uploading video  
- Communicating with backend  
- Showing transcript + scores  

### Backend â€” `src/backend/main.py`
FastAPI backend with:
- `POST /analyze` endpoint  
- Temporary file handling  
- AI scoring pipeline connection  
- JSON output formatting  

### AI Pipeline â€” `src/ai/analyze.py`
Handles:
- AssemblyAI transcription  
- Groq LLaMA scoring  
- Weighted computation  
- Suggestion generation  

### Documentation â€” `/docs`
Includes:
- `architecture.md`  
- `technical_summary.md`  
- `IntelliTeach.pdf`  

---

# ğŸ“ Folder Structure

```
IntelliTeach-AI/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ frontend/
â”‚   â”‚   â””â”€â”€ app.py
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â””â”€â”€ analyze.py
â”‚   â””â”€â”€ utils/
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ technical_summary.md
â”‚   â”œâ”€â”€ IntelliTeach.pdf
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

# âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Install dependencies
```
pip install -r requirements.txt
```

### 2ï¸âƒ£ Add API Keys (PowerShell)
```
setx ASSEMBLYAI_API_KEY "your-assemblyai-key"
setx GROQ_API_KEY "your-groq-key"
```

Restart PowerShell afterward.

### 3ï¸âƒ£ Run the backend
```
python -m uvicorn src.backend.main:app --reload --port 8000
```

Health check URL:
http://localhost:8000/health

Expected output:
```
{"status": "ok", "message": "Free version running!"}
```

### 4ï¸âƒ£ Run the frontend
```
streamlit run src/frontend/app.py
```

Upload a short MP4 to view transcript + scorecard.

---

# ğŸ§ª API Documentation

### POST /analyze
Upload a video and receive JSON scoring output.

Example:
```
curl -X POST http://localhost:8000/analyze -F "file=@sample.mp4"
```

Response:
```json
{
  "ok": true,
  "result": {
    "clarity": 82,
    "engagement": 75,
    "confidence": 80,
    "technical": 70,
    "interaction": 65,
    "overall": 75.4,
    "suggestions": ["Improve pacing", "Increase use of examples"],
    "transcript": "Full transcript text here..."
  }
}
```

---

# ğŸ“¦ Dependencies

- fastapi  
- uvicorn  
- python-multipart  
- requests  
- assemblyai  
- groq  
- streamlit  
- pydantic  

(Version details in `requirements.txt`.)

---

# ğŸ‘¥ Contributors

All contributors worked with equal responsibility across AI, backend, frontend, and documentation.

- **Charu Malik** â€” AI Pipeline â€¢ Backend Integration â€¢ Documentation  
- **Khushi Wadhwa** â€” Frontend Interface â€¢ User Workflow â€¢ Documentation  
- **Richa Singh** â€” Architecture Planning â€¢ Research â€¢ Quality Review  
